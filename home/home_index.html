<!DOCTYPE html>
<html lang="en" dir="ltr"> 
<head>
    <!--Allows other browsers to open the website-->
    <meta http-equiv="x-ua-compatible" content="IE=edge">
    <!--Its a refrenece to the language we're using(keyboard format)-->
    <meta charset="UTF-8">
    <!--Scales the websites size to fit any device-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!--Tab title-->
    <title>
        New Website
    </title>
    <!--Links html and css-->
    <link rel="stylesheet" href="notes_styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100&family=Poppins:wght@300&display=swap" rel="stylesheet">

</head>
<body>
    <div>
        <p><a href="/index.html">home</a></p>
    </div>

    <div>
        <p>I am a software engineer at <a>Waymo</a>, working on autonomous driving perception and mapping. 
            Previously, I was a postdoctoral scholar in the <a>Platform Lab</a> at <a>Stanford University</a>, advised by <a>Prof. Sachin Katti</a>. 
            My research focuses on networked systems problems at the intersection of machine learning, 
            cyber-physical systems, edge computing, mobile sensing, and networking. 
            I received my Ph.D. from <a>Networked Systems Lab</a> at <a>University of Southern California</a>, 
            advised by <a>Prof. Ramesh Govindan</a>. During my Ph.D., I was also privileged with close collaboration with <a>Prof. Konstantinos Psounis</a>, 
            and <a>Prof. Marco Gruteser</a>. My dissertation, titled <i>“Networked Cooperative Perception: 
            Towards Robust and Efficient Autonomous Driving”</i>, presents systems and 
            algorithms that enable cooperative perception among networked vehicles and infrastructure sensors that can substantially augment perception and 
            driving capabilities.</p>
         
        <p><a>[CV]</a> <a>[Google Scholar]</a> <a>[Dissertation]</a></p>
    </div>

    <div>    
        <div>
            <p> Research Highlights:</p>
            <ul>
                <li><b>Cooperative Autonomy:</b> AVR [<a>Mobisys'18</a>], CarMap [<a>NSDI'20</a>], Coopernaut [<a>CVPR'22</a>], AutoCast [<a>Mobisys'22</a>]</li>
                <li><b>System for Edge ML:</b> FedML [<a>NeurIPS'20(SpicyFL)</a>], ML-EXray [<a>MLSys'22</a>], MCAL [<a>ICLR'23</a>]</li>
                <li><b>Video Delivery & Analytics:</b> CoBCast [<a>Mobihoc'16</a>], Kestrel [<a>IoTDI'18</a>]</li>
                <li><b>Vehicular Sensing:</b> CarLog [<a>Sensys'14</a>], CarLoc [<a>Sensys'15</a>], ContextSensing [<a>TVT'17</a>]</li>
                
            </ul>
        </div>

        <div>
            <p>Recent News:</p>
            <ul>
                <li>Jan 2023: <a></a>MCAL accepted to ICLR' 23</li>
                <li>Dec 2022: Served as a TPC member for Mobisys'23, AAAI'23 and ICPADS'23, reviewer for CVPR'23, ICRA'23, and CoRL'23</li>
                <li>Sep 2022: Invited talk at the IEEE MFI'22 1st <a>Cooperative Perception Workshop</a></li>
                <li>Aug 2022: <a>ML-EXray</a> received the <a>Outstanding Paper Award</a> from MLSys'22</li>
                <li>Jun 2022: Crowdsourced image processing accepted to IEEE Transactions on Mobile Computing (<a>TMC</a>)</li>
                <li>Mar 2022: <a>ML-EXray</a> accepted as a talk at <a>Kubernetes on Edge Day Europe 2022</a></li>
                <li>Mar 2022: <a>AutoCast</a> accepted to Mobisys' 22</li>
                <li>Mar 2022: <a>Coopernaut</a> accepted to CVPR' 22</li>
                <li>Jan 2022: <a>ML-EXray</a> accepted to MLSys' 22</li>
                <li>Sep 2021: Teaching <a>Stanford EE292D: ML on Embedded Systems</a> with Prof. Katti, Prof. Asgar and Pete Warden for Fall 2021</li>
                <li>Aug 2021: Organizing a <a>tutorial on 3D sensing</a> at IEEE SmartComp'21</li>
            </ul>
        </div>
    </div>
</body>
</html>